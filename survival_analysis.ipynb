{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "421e02c6d7af4deba17b849fbd3e68f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a73314d3e1d54956b970cf1305976aa9",
              "IPY_MODEL_e7bad70c56bc42219927ddf1164bce58",
              "IPY_MODEL_29e7aac9c15f4dcfbb6a292162fd2e44"
            ],
            "layout": "IPY_MODEL_7b3418eac18c45988b672e5f62de29e3"
          }
        },
        "a73314d3e1d54956b970cf1305976aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b3b60fb31cd4df89398755602e98a1a",
            "placeholder": "​",
            "style": "IPY_MODEL_9dd564ec3be246449e2ffd533bc7b324",
            "value": "100%"
          }
        },
        "e7bad70c56bc42219927ddf1164bce58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9de49499ba0f406d8e7aea2b6b39160a",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_811223a3da7e4a159c2884c5c9e3cd02",
            "value": 46830571
          }
        },
        "29e7aac9c15f4dcfbb6a292162fd2e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51d8f2d71e124297863945503a715a59",
            "placeholder": "​",
            "style": "IPY_MODEL_48c4ef176cd144e5a78196b0b5443a9c",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 105MB/s]"
          }
        },
        "7b3418eac18c45988b672e5f62de29e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b3b60fb31cd4df89398755602e98a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dd564ec3be246449e2ffd533bc7b324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9de49499ba0f406d8e7aea2b6b39160a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "811223a3da7e4a159c2884c5c9e3cd02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51d8f2d71e124297863945503a715a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48c4ef176cd144e5a78196b0b5443a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Packages and Imports"
      ],
      "metadata": {
        "id": "IY6mtvqjob0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14T3Ns6b87J4",
        "outputId": "b5562708-a388-4ae9-e120-c1e7643126a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom\n",
        "!pip install nipype\n",
        "!pip install dcm2niix\n",
        "!pip install nibabel\n",
        "!pip install pycox\n",
        "!pip install torchtuples\n",
        "!pip install lifelines\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkZs4RV0ovup",
        "outputId": "10d64aba-13e8-4dea-9758-5db6df06bb9c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydicom\n",
            "  Downloading pydicom-2.3.1-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 4.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nipype\n",
            "  Downloading nipype-1.8.5-py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from nipype) (1.21.6)\n",
            "Collecting traits!=5.0,<6.4,>=4.6\n",
            "  Downloading traits-6.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (5.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1 MB 29.5 MB/s \n",
            "\u001b[?25hCollecting simplejson>=3.8.0\n",
            "  Downloading simplejson-3.18.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 48.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.8/dist-packages (from nipype) (7.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.8/dist-packages (from nipype) (1.7.3)\n",
            "Collecting looseversion\n",
            "  Downloading looseversion-1.0.2-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from nipype) (21.3)\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from nipype) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.8/dist-packages (from nipype) (2.8.2)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from nipype) (3.8.2)\n",
            "Collecting prov>=1.5.2\n",
            "  Downloading prov-2.0.0-py3-none-any.whl (421 kB)\n",
            "\u001b[K     |████████████████████████████████| 421 kB 50.7 MB/s \n",
            "\u001b[?25hCollecting rdflib>=5.0.0\n",
            "  Downloading rdflib-6.2.0-py3-none-any.whl (500 kB)\n",
            "\u001b[K     |████████████████████████████████| 500 kB 51.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from nipype) (2.8.8)\n",
            "Collecting etelemetry>=0.2.0\n",
            "  Downloading etelemetry-0.3.0-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: nibabel>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from nipype) (3.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from etelemetry>=0.2.0->nipype) (2.23.0)\n",
            "Collecting ci-info>=0.2\n",
            "  Downloading ci_info-0.3.0-py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: lxml>=3.3.5 in /usr/local/lib/python3.8/dist-packages (from prov>=1.5.2->nipype) (4.9.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.8/dist-packages (from pydot>=1.2.3->nipype) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.2->nipype) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from rdflib>=5.0.0->nipype) (57.4.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 525 kB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->etelemetry>=0.2.0->nipype) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->etelemetry>=0.2.0->nipype) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->etelemetry>=0.2.0->nipype) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->etelemetry>=0.2.0->nipype) (2.10)\n",
            "Installing collected packages: isodate, rdflib, ci-info, traits, simplejson, prov, looseversion, etelemetry, nipype\n",
            "Successfully installed ci-info-0.3.0 etelemetry-0.3.0 isodate-0.6.1 looseversion-1.0.2 nipype-1.8.5 prov-2.0.0 rdflib-6.2.0 simplejson-3.18.0 traits-6.3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dcm2niix\n",
            "  Downloading dcm2niix-1.0.20220715.tar.gz (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 4.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting miutil[web]\n",
            "  Downloading miutil-0.10.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tqdm>=4.40.0 in /usr/local/lib/python3.8/dist-packages (from miutil[web]->dcm2niix) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from miutil[web]->dcm2niix) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->miutil[web]->dcm2niix) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->miutil[web]->dcm2niix) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->miutil[web]->dcm2niix) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->miutil[web]->dcm2niix) (2.10)\n",
            "Building wheels for collected packages: dcm2niix\n",
            "  Building wheel for dcm2niix (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dcm2niix: filename=dcm2niix-1.0.20220715-cp38-cp38-linux_x86_64.whl size=601060 sha256=fa2421be96648c7c9f29e77e094c115574b12528fc6e132decd52902abc4fe77\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/ad/be/de4334a6bec64465e158e35614ccbff0fbd9080f684c1daace\n",
            "Successfully built dcm2niix\n",
            "Installing collected packages: miutil, dcm2niix\n",
            "Successfully installed dcm2niix-1.0.20220715 miutil-0.10.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.8/dist-packages (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.8/dist-packages (from nibabel) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycox\n",
            "  Downloading pycox-0.2.3-py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: feather-format>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from pycox) (0.4.1)\n",
            "Requirement already satisfied: numba>=0.44 in /usr/local/lib/python3.8/dist-packages (from pycox) (0.56.4)\n",
            "Collecting torchtuples>=0.2.0\n",
            "  Downloading torchtuples-0.2.2-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 660 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from pycox) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.8/dist-packages (from pycox) (1.0.2)\n",
            "Collecting py7zr>=0.11.3\n",
            "  Downloading py7zr-0.20.2-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from pycox) (3.1.0)\n",
            "Requirement already satisfied: pyarrow>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from feather-format>=0.4.0->pycox) (9.0.0)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.8/dist-packages (from h5py>=2.9.0->pycox) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.44->pycox) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.44->pycox) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.44->pycox) (5.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from py7zr>=0.11.3->pycox) (5.4.8)\n",
            "Collecting texttable\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting multivolumefile>=0.2.3\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting inflate64>=0.3.1\n",
            "  Downloading inflate64-0.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1\n",
            "  Downloading pyppmd-1.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 64.7 MB/s \n",
            "\u001b[?25hCollecting pybcj>=0.6.0\n",
            "  Downloading pybcj-1.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting brotli>=1.0.9\n",
            "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[K     |████████████████████████████████| 357 kB 58.2 MB/s \n",
            "\u001b[?25hCollecting pycryptodomex>=3.6.6\n",
            "  Downloading pycryptodomex-3.16.0-cp35-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 35.9 MB/s \n",
            "\u001b[?25hCollecting pyzstd>=0.14.4\n",
            "  Downloading pyzstd-0.15.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
            "\u001b[K     |████████████████████████████████| 378 kB 60.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pycox) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pycox) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pycox) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->pycox) (2022.12.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.2->pycox) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.2->pycox) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.2->pycox) (1.7.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.8/dist-packages (from torchtuples>=0.2.0->pycox) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.8/dist-packages (from torchtuples>=0.2.0->pycox) (1.3.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.2->torchtuples>=0.2.0->pycox) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.44->pycox) (3.11.0)\n",
            "Installing collected packages: texttable, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, brotli, torchtuples, py7zr, pycox\n",
            "Successfully installed brotli-1.0.9 inflate64-0.3.1 multivolumefile-0.2.3 py7zr-0.20.2 pybcj-1.0.1 pycox-0.2.3 pycryptodomex-3.16.0 pyppmd-1.0.0 pyzstd-0.15.3 texttable-1.6.7 torchtuples-0.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtuples in /usr/local/lib/python3.8/dist-packages (0.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.8/dist-packages (from torchtuples) (1.3.5)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.8/dist-packages (from torchtuples) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.8/dist-packages (from torchtuples) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.3->torchtuples) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.3->torchtuples) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.3->torchtuples) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.3->torchtuples) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.2->torchtuples) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.3->torchtuples) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lifelines\n",
            "  Downloading lifelines-0.27.4-py3-none-any.whl (349 kB)\n",
            "\u001b[K     |████████████████████████████████| 349 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from lifelines) (1.21.6)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.8/dist-packages (from lifelines) (3.2.2)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from lifelines) (1.3.5)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.8/dist-packages (from lifelines) (1.5)\n",
            "Collecting autograd-gamma>=0.3\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "Collecting formulaic>=0.2.2\n",
            "  Downloading formulaic-0.5.2-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from lifelines) (1.7.3)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.8/dist-packages (from autograd>=1.5->lifelines) (0.16.0)\n",
            "Collecting interface-meta>=1.2.0\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from formulaic>=0.2.2->lifelines) (4.4.0)\n",
            "Collecting graphlib-backport>=1.0.0\n",
            "  Downloading graphlib_backport-1.0.3-py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: astor>=0.8 in /usr/local/lib/python3.8/dist-packages (from formulaic>=0.2.2->lifelines) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.8/dist-packages (from formulaic>=0.2.2->lifelines) (1.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0->lifelines) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0->lifelines) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0->lifelines) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0->lifelines) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.0->lifelines) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0->lifelines) (1.15.0)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4048 sha256=c7c3040955e8d2547490aef811d472242fbfe6e4e7233e7af73bd689412bc078\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/a2/b6/582cfdfbeeccd469504a01af3bb952fd9e7eccba40995eafea\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: interface-meta, graphlib-backport, formulaic, autograd-gamma, lifelines\n",
            "Successfully installed autograd-gamma-0.5.0 formulaic-0.5.2 graphlib-backport-1.0.3 interface-meta-1.3.0 lifelines-0.27.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pydicom as di \n",
        "import os\n",
        "from os import listdir\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from skimage.transform import resize\n",
        "from subprocess import call\n",
        "import re\n",
        "from functools import reduce\n",
        "import shutil\n",
        "import nibabel as nib\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "#Model 1 \n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch import flatten\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn_pandas import DataFrameMapper \n",
        "import torchtuples as tt\n",
        "from pycox.datasets import metabric\n",
        "from pycox.models import DeepHitSingle\n",
        "from pycox.evaluation import EvalSurv\n",
        "\n",
        "\n",
        "import scipy.io\n",
        "\n",
        "#Model 3\n",
        "\n",
        "import sys, os, datetime, h5py\n",
        "import numpy as np\n",
        "from scipy import io\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, model_from_json\n",
        "from tensorflow.keras.layers import Input,InputLayer, Dense,  Dropout, Activation, Concatenate, Lambda\n",
        "#from tensorflow.python.keras.summary import merge\n",
        "# from tensorflow.keras.utils import plot_model, multi_gpu_model\n",
        "from tensorflow.keras.callbacks import CSVLogger, LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from functools import partial, update_wrapper\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from lifelines.utils import concordance_index\n",
        "\n",
        "\n",
        "import nipype.interfaces.fsl as fsl\n",
        "\n",
        "\n",
        "from nipype.interfaces import fsl\n",
        "from nipype.testing import example_data"
      ],
      "metadata": {
        "id": "QPIlAWgmowwM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/content/ADNI\""
      ],
      "metadata": {
        "id": "8FiifDDIp-aX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode='mat'\n",
        "modelMode='eval'"
      ],
      "metadata": {
        "id": "FOBeJwmV9FrU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metadata"
      ],
      "metadata": {
        "id": "bEo9eJEMo2Pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata0 = pd.read_csv('/content/gdrive/MyDrive/dataset/Survival/Year0/healthy_and_ad_patient_0_12_01_2022.csv', sep=',', header=0)\n",
        "metadata1 = pd.read_csv('/content/gdrive/MyDrive/dataset/Survival/Year1/healthy_and_ad_patient_1_12_01_2022.csv', sep=',', header=0)\n",
        "metadata2 = pd.read_csv('/content/gdrive/MyDrive/dataset/Survival/Year2/healthy_and_ad_patient_2_12_01_2022.csv', sep=',', header=0)\n",
        "metadata3 = pd.read_csv('/content/gdrive/MyDrive/dataset/Survival/Year3/healty_and_ad_patient_3_12_01_2022.csv', sep=',', header=0)\n",
        "metadata4 = pd.read_csv('/content/gdrive/MyDrive/dataset/Survival/Year4/healthy_and_ad_patient_4_12_01_2022.csv', sep=',', header=0)\n",
        "metadata5 = pd.read_csv('/content/gdrive/MyDrive/dataset/Survival/Year5/heathy_and_ad_patient_5_12_01_2022.csv', sep=',', header=0)"
      ],
      "metadata": {
        "id": "c7NAptz4o4S0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T=6"
      ],
      "metadata": {
        "id": "XRNf73RhrsVJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genetic_data=pd.read_csv('/content/content/ADNIGenetic.csv')"
      ],
      "metadata": {
        "id": "4UgMsjsbo9OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata=pd.read_csv('/content/gdrive/MyDrive/dataset/Survival/Merged/healthy_and_ad_patient.csv', sep=',', header=0)"
      ],
      "metadata": {
        "id": "KZyj69Dn9me9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1\n"
      ],
      "metadata": {
        "id": "tIR1nv2soh6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "ILX87WTBq8-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "durations=metadata['durations']\n",
        "event=metadata['event']\n",
        "covariates=metadata['covariates']"
      ],
      "metadata": {
        "id": "OXDULPwS9wOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replace with your path\n",
        "if mode == 'mat':\n",
        "  x_train=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/basic_data/features_basic_train.mat')\n",
        "  x_test=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/basic_data/features_basic_test.mat')\n",
        "  y_train=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/basic_data/y_basic_train.mat')\n",
        "  y_test=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/basic_data/y_basic_test.mat')\n",
        "  x_train = np.array( x_train[\"data\"], dtype = 'float32' )\n",
        "  x_test = np.array( x_test[\"data\"], dtype = 'float32' )\n",
        "  y_train = np.array( y_train[\"data\"], dtype = 'float32' )\n",
        "  y_test = np.array( y_test[\"data\"], dtype = 'float32' )\n",
        "\n",
        "else:\n",
        "  labels=list(zip(durations, event))\n",
        "  x_train,x_test,y_train,y_test=train_test_split(covariates,labels,test_size=0.2)\n",
        "d_train=np.array([y[0] for y in y_train], dtype='float32')\n",
        "e_train=np.array([y[1] for y in y_train], dtype='float32')\n",
        "d_test=np.array([y[0] for y in y_test], dtype='float32')\n",
        "e_test=np.array([y[1] for y in y_test], dtype='float32')"
      ],
      "metadata": {
        "id": "7D7lzLTIsIr1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network"
      ],
      "metadata": {
        "id": "Wh7Cb3zSq_lN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(Module):\n",
        "  def __init__(self, numChannels, classes):\n",
        "    # call the parent constructor\n",
        "    super(CNN, self).__init__()\n",
        "    # initialize first set of CONV => RELU => POOL layers\n",
        "    self.conv1 = Conv2d(in_channels=numChannels, out_channels=20,\n",
        "      kernel_size=(7, 7))\n",
        "    #224-5 + 1= 220\n",
        "    self.relu1 = ReLU()\n",
        "    self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "    #220/2=110\n",
        "    #110/2=55\n",
        "    # initialize second set of CONV => RELU => POOL layers\n",
        "    self.conv2 = Conv2d(in_channels=20, out_channels=50,\n",
        "      kernel_size=(5, 5))\n",
        "    #55-5+1=51\n",
        "    self.relu2 = ReLU()\n",
        "    self.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "    #51/2=25\n",
        "    self.conv3 = Conv2d(in_channels=50, out_channels=50,\n",
        "      kernel_size=(5, 5))\n",
        "    #25-5+1=21\n",
        "    # initialize first (and only) set of FC => RELU layers\n",
        "    self.fc1 = Linear(in_features=21*21*50, out_features=500)\n",
        "    self.relu3 = ReLU()\n",
        "    # initialize our softmax classifier\n",
        "    self.fc2 = Linear(in_features=500, out_features=classes)\n",
        "    self.logSoftmax = LogSoftmax(dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "\t\t# pass the input through our first set of CONV => RELU =>\n",
        "\t\t# POOL layers\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    # pass the output from the previous layer through the second\n",
        "    # set of CONV => RELU => POOL layers\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu2(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.conv3(x)\n",
        "    # flatten the output from the previous layer and pass it\n",
        "    # through our only set of FC => RELU layers\n",
        "    x = flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu3(x)\n",
        "    # pass the output to our softmax classifier to get our output\n",
        "    # predictions\n",
        "    x = self.fc2(x)\n",
        "    output = self.logSoftmax(x)\n",
        "    # return the output predictions\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "s5vgmrSYrDGf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network Params"
      ],
      "metadata": {
        "id": "bkL8zY0WrE8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numClasses=T\n",
        "numChannels=3"
      ],
      "metadata": {
        "id": "oe7RFal_rpTY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "xTKYnZRmrIAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net=CNN(3, 6)\n",
        "labtrans = DeepHitSingle.label_transform(T)\n",
        "labels = labtrans.fit_transform(d_train,e_train)\n",
        "model = DeepHitSingle(net, tt.optim.Adam, alpha=0.2, sigma=0.1, duration_index=labtrans.cuts)\n",
        "model.load_net('/content/gdrive/MyDrive/dataset/Survival/Models/basic.pt')\n",
        "batch_size = 12\n"
      ],
      "metadata": {
        "id": "sreJu62ysEUr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_finder = model.lr_finder(x_train, labels, batch_size, tolerance=3)\n",
        "lr_finder.get_best_lr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9BE94AasOT_",
        "outputId": "ed20e36c-ac09-43c1-b0a0-0aa9dd7234a7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001321941148466034"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if modelMode == 'train':\n",
        "  model.optimizer.set_lr(0.00008)\n",
        "  batch_size = 12\n",
        "  epochs = 100\n",
        "  callbacks = [tt.callbacks.EarlyStopping()]\n",
        "  log = model.fit(x_train, labels, batch_size, epochs,callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnGBcXWtsPUf",
        "outputId": "815043df-04ec-457d-93b1-bd557d834fc2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[13s / 13s],\t\ttrain_loss: 0.1028\n",
            "1:\t[11s / 24s],\t\ttrain_loss: 0.0874\n",
            "2:\t[11s / 35s],\t\ttrain_loss: 0.0809\n",
            "3:\t[12s / 47s],\t\ttrain_loss: 0.0668\n",
            "4:\t[11s / 58s],\t\ttrain_loss: 0.0624\n",
            "5:\t[13s / 1m:11s],\t\ttrain_loss: 0.0557\n",
            "6:\t[11s / 1m:22s],\t\ttrain_loss: 0.0512\n",
            "7:\t[11s / 1m:34s],\t\ttrain_loss: 0.0442\n",
            "8:\t[14s / 1m:48s],\t\ttrain_loss: 0.0381\n",
            "9:\t[13s / 2m:1s],\t\ttrain_loss: 0.0349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "fbxVsdQNrPeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "surv = model.interpolate(6).predict_surv_df(x_test)\n",
        "ev = EvalSurv(surv, d_test, e_test, censor_surv='km')\n",
        "ev.concordance_td('antolini')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gnset_WU_kt-",
        "outputId": "2416e522-358a-4b67-b864-7a6d9e37f264"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6956521739130435"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model and data"
      ],
      "metadata": {
        "id": "2b8mljxfuToF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_net('basic.pt')\n",
        "scipy.io.savemat('/content/basic_data/features_basic_test.mat', {\"data\":x_test})\n",
        "scipy.io.savemat('/content/basic_data/features_basic_train.mat', {\"data\":x_train})\n",
        "scipy.io.savemat('/content/basic_data/y_basic_train.mat', {\"data\":y_train})\n",
        "scipy.io.savemat('/content/basic_data/y_basic_test.mat', {\"data\":y_test})"
      ],
      "metadata": {
        "id": "72zjbUrIuUxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2"
      ],
      "metadata": {
        "id": "40158vgSok-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "nsrts8PXt_tE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "durations=metadata['durations']\n",
        "event=metadata['event']\n",
        "covariates=metadata['covariates']"
      ],
      "metadata": {
        "id": "PjQFNdCIBbSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replace with your path\n",
        "if mode == 'mat':\n",
        "  x_train=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/longitudnal_data/features_train.mat')\n",
        "  x_test=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/longitudnal_data/features_test.mat')\n",
        "  y_train=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/longitudnal_data/y_train.mat')\n",
        "  y_test=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/longitudnal_data/y_test.mat')\n",
        "  x_train = np.array( x_train[\"data\"], dtype = 'float32' )\n",
        "  x_test = np.array( x_test[\"data\"], dtype = 'float32' )\n",
        "  y_train = np.array( y_train[\"data\"], dtype = 'float32' )\n",
        "  y_test = np.array( y_test[\"data\"], dtype = 'float32' )\n",
        "\n",
        "else:\n",
        "  labels=list(zip(durations, event))\n",
        "  x_train,x_test,y_train,y_test=train_test_split(covariates,labels,test_size=0.2)\n",
        "d_train=np.array([y[0] for y in y_train], dtype='float32')\n",
        "e_train=np.array([y[1] for y in y_train], dtype='float32')\n",
        "d_test=np.array([y[0] for y in y_test], dtype='float32')\n",
        "e_test=np.array([y[1] for y in y_test], dtype='float32')\n"
      ],
      "metadata": {
        "id": "DtgPyPjCBbSn"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, x_test.shape, d_train.shape, d_test.shape, e_train.shape, e_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6Xum4iWJZEj",
        "outputId": "00088d15-8d6c-470a-8458-5bf51f13af5f"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(201, 125440) (51, 125440) (201,) (51,) (201,) (51,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network"
      ],
      "metadata": {
        "id": "aJIPR9k0uByG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Renet"
      ],
      "metadata": {
        "id": "Ed5_AFSBujgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "feature_extractor = torch.nn.Sequential(*list(resnet.children())[:-2])\n",
        "for param in feature_extractor.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "421e02c6d7af4deba17b849fbd3e68f4",
            "a73314d3e1d54956b970cf1305976aa9",
            "e7bad70c56bc42219927ddf1164bce58",
            "29e7aac9c15f4dcfbb6a292162fd2e44",
            "7b3418eac18c45988b672e5f62de29e3",
            "0b3b60fb31cd4df89398755602e98a1a",
            "9dd564ec3be246449e2ffd533bc7b324",
            "9de49499ba0f406d8e7aea2b6b39160a",
            "811223a3da7e4a159c2884c5c9e3cd02",
            "51d8f2d71e124297863945503a715a59",
            "48c4ef176cd144e5a78196b0b5443a9c"
          ]
        },
        "id": "QDJOn99vulvH",
        "outputId": "2f5c6b47-edae-44d6-f22b-4439db87543d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "421e02c6d7af4deba17b849fbd3e68f4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network params"
      ],
      "metadata": {
        "id": "icLWzvdIuC5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_features = 5*25088\n",
        "num_nodes = [32, 32]\n",
        "out_features = labtrans.out_features\n",
        "batch_norm = True\n",
        "dropout = 0.1"
      ],
      "metadata": {
        "id": "Zx_ys6RSuwc9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labtrans = DeepHitSingle.label_transform(6)\n",
        "labels = labtrans.fit_transform(d_train,e_train)\n",
        "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
        "model2 = DeepHitSingle(net, tt.optim.Adam, alpha=0.2, sigma=0.1, duration_index=labtrans.cuts)"
      ],
      "metadata": {
        "id": "sEi5IxBxu0Lx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.load_net('/content/gdrive/MyDrive/dataset/Survival/Models/longitudnal.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yfk__8osB3Y0",
        "outputId": "afd4912a-9df6-4e93-9ac0-14ea4ac67bc8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPVanilla(\n",
              "  (net): Sequential(\n",
              "    (0): DenseVanillaBlock(\n",
              "      (linear): Linear(in_features=125440, out_features=32, bias=True)\n",
              "      (activation): ReLU()\n",
              "      (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): DenseVanillaBlock(\n",
              "      (linear): Linear(in_features=32, out_features=32, bias=True)\n",
              "      (activation): ReLU()\n",
              "      (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "m0x8r3mWuHo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if mode != 'mat':\n",
        "  model2.optimizer.set_lr(0.00007)\n",
        "  epochs = 100\n",
        "  callbacks = [tt.callbacks.EarlyStopping()]\n",
        "  log = model2.fit(x_train, labels, 12, epochs, callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyooiNNYvCO3",
        "outputId": "03bb5951-6d4e-439a-ba39-14691fec2bf1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[1s / 1s],\t\ttrain_loss: 0.1550\n",
            "1:\t[1s / 2s],\t\ttrain_loss: 0.1221\n",
            "2:\t[1s / 3s],\t\ttrain_loss: 0.0979\n",
            "3:\t[1s / 4s],\t\ttrain_loss: 0.0950\n",
            "4:\t[1s / 5s],\t\ttrain_loss: 0.0883\n",
            "5:\t[1s / 6s],\t\ttrain_loss: 0.0817\n",
            "6:\t[1s / 7s],\t\ttrain_loss: 0.0773\n",
            "7:\t[1s / 8s],\t\ttrain_loss: 0.0725\n",
            "8:\t[1s / 10s],\t\ttrain_loss: 0.0690\n",
            "9:\t[1s / 11s],\t\ttrain_loss: 0.0688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "lH6ZGjCQuLD1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBCfo80lVm-h",
        "outputId": "6ef4e093-8e25-4a0c-be7c-f0ef9e5d64ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.691304347826087"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "surv = model2.interpolate(6).predict_surv_df(x_test)\n",
        "ev = EvalSurv(surv, d_test, e_test, censor_surv='km')\n",
        "ev.concordance_td('antolini')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model and data"
      ],
      "metadata": {
        "id": "hzqZB0TRuNxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scipy.io.savemat('/content/longitudnal_data/features_test.mat', {\"data\":x_test})\n",
        "scipy.io.savemat('/content/longitudnal_data/features_train.mat', {\"data\":x_train})\n",
        "scipy.io.savemat('/content/longitudnal_data/y_train.mat', {\"data\":y_train})\n",
        "scipy.io.savemat('/content/longitudnal_data/y_test.mat', {\"data\":y_test})\n",
        "\n",
        "model.save_net('longitudnal.pt')"
      ],
      "metadata": {
        "id": "TrUt939OwYut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3"
      ],
      "metadata": {
        "id": "4U69Nmf3onC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "TchFV84hotqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=metadata['covariates']\n",
        "E=metadata['event']\n",
        "mask=metadata['mask']"
      ],
      "metadata": {
        "id": "LOyB1HKEDQ7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replace with your path\n",
        "if mode == 'mat':\n",
        "  x_train=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/deep_surv_data/features_train.mat')\n",
        "  x_test=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/deep_surv_data/features_test.mat')\n",
        "  y_train=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/deep_surv_data/y_train.mat')\n",
        "  y_test=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/deep_surv_data/y_test.mat')\n",
        "  mask_train=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/deep_surv_data/mask_test.mat')\n",
        "  mask_test=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/deep_surv_data/mask_train.mat')\n",
        "  e_train=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/deep_surv_data/e_train.mat')\n",
        "  e_test=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/deep_surv_data/e_test.mat')\n",
        "\n",
        "\n",
        "  x_train = np.array( x_train[\"data\"], dtype = 'float32' )\n",
        "  x_test = np.array( x_test[\"data\"], dtype = 'float32' )\n",
        "  y_train = np.array( y_train[\"data\"], dtype = 'float32' )\n",
        "  y_test = np.array( y_test[\"data\"], dtype = 'float32' )\n",
        "  mask_train = np.array( mask_train[\"data\"], dtype = 'float32' )\n",
        "  mask_test = np.array( mask_test[\"data\"], dtype = 'float32' )\n",
        "  e_train = np.array( e_train[\"data\"], dtype = 'float32' )\n",
        "  e_test = np.array( e_test[\"data\"], dtype = 'float32' )\n",
        "\n",
        "\n",
        "else:\n",
        "  x_train,x_test,y_train,y_test,mask_train,mask_test,e_train,e_test=train_test_split(x,E,mask,event,test_size=0.2)\n"
      ],
      "metadata": {
        "id": "f1ZgtB_iDMgc"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network"
      ],
      "metadata": {
        "id": "XqJuT2gdwbOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resnet"
      ],
      "metadata": {
        "id": "9IvSj4Zjw1sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Resnet\n",
        "fe = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "fe=torch.nn.Sequential(*(list(fe.children())[:-1]))\n",
        "fe.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onOeGbCcwznp",
        "outputId": "f12144ac-a425-418a-d668-08dc506e1130"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network Params"
      ],
      "metadata": {
        "id": "m9moVemAxD7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn=254\n",
        "n_features=512\n",
        "DROPOUT_RATIO = 0.5\n",
        "J = 5"
      ],
      "metadata": {
        "id": "jZrdNuM8xF7E"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "\n",
        "with tf.device(\"/cpu:0\"):\n",
        "\n",
        "    def output_of_lambda(input_shape):\n",
        "        shape = list(input_shape)\n",
        "        return (shape[0], J)\n",
        "\n",
        "    def weibull_cdf(parameters):\n",
        "        m = parameters[:,0]\n",
        "        s = tf.maximum( parameters[:,1], 0.001 )\n",
        "        output_list = []\n",
        "        for num in range( J ):\n",
        "            Time   = tf.constant( num, dtype=\"float32\")\n",
        "            e_Time = tf.pow( Time, m )\n",
        "            s_Time = tf.negative( tf.divide( e_Time, s) )\n",
        "            x = tf.subtract( tf.constant(1, dtype=\"float32\") , tf.exp( s_Time ) ) # F(t) = 1 - exp(-(t-g)^m/s) #ref http://www.mogami.com/notes/weibull.html\n",
        "            output_list.append ( x )\n",
        "        return tf.stack(output_list, axis=1)\n",
        "\n",
        "    def generator_loss(y_true, y_pred, weights):  # y_true's shape=(batch_size, row, col, ch)\n",
        "        #loss = tf.cumsum( tf.multiply( tf.square( tf.subtract( y_pred, y_true ) ), weights ), axis=1, reverse=True)[:,0]\n",
        "        log_p = tf.math.log( tf.add( y_pred,  tf.constant(1.0) ) )\n",
        "        log_t = tf.math.log( tf.add( y_true,  tf.constant(1.0) ) )\n",
        "        loss = tf.cumsum( tf.multiply( tf.square( tf.subtract( log_p, log_t ) ), weights ), axis=1, reverse=True)[:,0]\n",
        "        return loss\n",
        "\n",
        "    def wrapped_generator_loss(func, *args, **kwargs):\n",
        "        partial_generator_loss = partial(generator_loss, *args, **kwargs)\n",
        "        update_wrapper(partial_generator_loss, generator_loss)\n",
        "        return partial_generator_loss\n",
        "\n",
        "    inputs = Input((n_features,), name='inputs')\n",
        "    x1 = Dense(units=32, activation='relu', name='hidden_layer1',\n",
        "                kernel_regularizer=regularizers.l1_l2(0.001))(inputs)\n",
        "    x1 = Dropout(DROPOUT_RATIO)(x1)\n",
        "    x2 = Dense(units=32, activation='relu', name='hidden_layer2',\n",
        "                kernel_regularizer=regularizers.l1_l2(0.001))(x1)\n",
        "    x2 = Dropout(DROPOUT_RATIO)(x2)\n",
        "    x3 = Dense(units=32, activation='relu', name='hidden_layer3',\n",
        "                kernel_regularizer=regularizers.l1_l2(0.001))(x2)\n",
        "    x3 = Dropout(DROPOUT_RATIO)(x3)\n",
        "    p1 = Dense(units=1, activation='softplus', name='param1_layer')(x3)\n",
        "    p2 = Dense(units=1, activation='relu', name='param2_layer')(x3)\n",
        "    parameters = Concatenate(name='params_layer')([p1, p2])\n",
        "    y_pred = Lambda(weibull_cdf, output_shape=output_of_lambda)(parameters)\n",
        "\n",
        "    mask_batch = Input((J,), name='mask_bartch')\n",
        "    L = wrapped_generator_loss(generator_loss, weights = mask_batch)\n",
        "\n",
        "    model = Model(inputs= [inputs, mask_batch], outputs = y_pred)\n",
        "    model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTCE6csFxlY8",
        "outputId": "bc89cd46-5b0f-4fbd-f3c6-68fc440e5c91"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " hidden_layer1 (Dense)          (None, 32)           16416       ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 32)           0           ['hidden_layer1[0][0]']          \n",
            "                                                                                                  \n",
            " hidden_layer2 (Dense)          (None, 32)           1056        ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 32)           0           ['hidden_layer2[0][0]']          \n",
            "                                                                                                  \n",
            " hidden_layer3 (Dense)          (None, 32)           1056        ['dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 32)           0           ['hidden_layer3[0][0]']          \n",
            "                                                                                                  \n",
            " param1_layer (Dense)           (None, 1)            33          ['dropout_11[0][0]']             \n",
            "                                                                                                  \n",
            " param2_layer (Dense)           (None, 1)            33          ['dropout_11[0][0]']             \n",
            "                                                                                                  \n",
            " params_layer (Concatenate)     (None, 2)            0           ['param1_layer[0][0]',           \n",
            "                                                                  'param2_layer[0][0]']           \n",
            "                                                                                                  \n",
            " mask_bartch (InputLayer)       [(None, 5)]          0           []                               \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 5)            0           ['params_layer[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 18,594\n",
            "Trainable params: 18,594\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/gdrive/MyDrive/dataset/Survival/Models/deepSurv2', compile=False)"
      ],
      "metadata": {
        "id": "alN0HTzexw4u"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "go9hNaX4wc2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_params = np.zeros([nn,2])\n",
        "c_index_test = np.zeros([J,1])\n",
        "outputfilename     = 'Training.csv'\n",
        "weightfilename     = 'WeightBest.h5'\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "features_train = scaler.transform(x_train)\n",
        "features_test = scaler.transform(x_test)\n",
        "checkpointer = ModelCheckpoint(filepath=weightfilename, monitor='loss', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "ix8TqJAFy4AR"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(patience=10,verbose=1)\n",
        "callbacks = []\n",
        "callbacks.append(early_stopping)\n",
        "adm = optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model.compile(optimizer=adm, loss=L)\n",
        "# model.run_eagerly = True\n",
        "if mode != 'mat':\n",
        "  model.fit([features_train, mask_train], y_train, batch_size=12, epochs = 100, callbacks=callbacks, verbose=0)\n",
        "  model.save_weights('Model_Weights_.h5')"
      ],
      "metadata": {
        "id": "ccqjpbcLy6Pa"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "mF8snqQpweLv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNf636avRC_b"
      },
      "outputs": [],
      "source": [
        "\n",
        "prob = model.predict([features_test, mask_test], batch_size=12)\n",
        "c_index = np.zeros([J])\n",
        "for num in range(J - 1) :\n",
        "    c_index[num+1] = concordance_index(y_test[:,num+1],1/prob[:,num+1])\n",
        "print( np.mean(c_index ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model and data"
      ],
      "metadata": {
        "id": "1cwHwplZwgAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scipy.io.savemat('/content/deep_surv_data/features_test.mat', {\"data\":x_test})\n",
        "scipy.io.savemat('/content/deep_surv_data/features_train.mat', {\"data\":x_train})\n",
        "scipy.io.savemat('/content/deep_surv_data/y_train.mat', {\"data\":y_train})\n",
        "scipy.io.savemat('/content/deep_surv_data/y_test.mat', {\"data\":y_test})\n",
        "\n",
        "scipy.io.savemat('/content/deep_surv_data/mask_test.mat', {\"data\":mask_train})\n",
        "scipy.io.savemat('/content/deep_surv_data/mask_train.mat', {\"data\":mask_test})\n",
        "scipy.io.savemat('/content/deep_surv_data/e_train.mat', {\"data\":e_train})\n",
        "scipy.io.savemat('/content/deep_surv_data/e_test.mat', {\"data\":e_test})"
      ],
      "metadata": {
        "id": "I6DeBqPq1GHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('deepSurv')"
      ],
      "metadata": {
        "id": "jljxvMmA1G68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4"
      ],
      "metadata": {
        "id": "6qRWKuhHoo68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "SMrz6mM01b3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if mode == 'mat':\n",
        "  x_train=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/data_gmv/features_gmv_train.mat')\n",
        "  x_test=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/data_gmv/features_gmv_test.mat')\n",
        "  d_train=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/data_gmv/d_gmv_train.mat')\n",
        "  d_test=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/data_gmv/d_gmv_test.mat')\n",
        "  e_train=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/data_gmv/event_gmv_train.mat')\n",
        "  e_test=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/data_gmv/event_gmv_test.mat')\n",
        "  x_train = np.array( x_train[\"data\"], dtype = 'float32' )\n",
        "  x_test = np.array( x_test[\"data\"], dtype = 'float32' )\n",
        "  d_train = np.array( d_train[\"data\"], dtype = 'float32' ).flatten()\n",
        "  d_test = np.array( d_test[\"data\"], dtype = 'float32' ).flatten()\n",
        "  e_train = np.array( e_train[\"data\"], dtype = 'float32' ).flatten()\n",
        "  e_test = np.array( e_test[\"data\"], dtype = 'float32' ).flatten()\n",
        "\n",
        "else:\n",
        "  labels=list(zip(durations, event))\n",
        "  x_train,x_test,y_train,y_test=train_test_split(covariates,labels,test_size=0.2)\n",
        "  d_train=np.array([y[0] for y in y_train], dtype='float32')\n",
        "  e_train=np.array([y[1] for y in y_train], dtype='float32')\n",
        "  d_test=np.array([y[0] for y in y_test], dtype='float32')\n",
        "  e_test=np.array([y[1] for y in y_test], dtype='float32')\n"
      ],
      "metadata": {
        "id": "0if910m81dOc"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, x_test.shape, d_train.shape, d_test.shape, e_train.shape, e_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdbuT7LbHXaP",
        "outputId": "74088d32-4958-4fb9-e3b5-6cba283d91aa"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(201, 125440) (51, 125440) (201,) (51,) (201,) (51,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network"
      ],
      "metadata": {
        "id": "_zLL7vK_1nIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labtrans = DeepHitSingle.label_transform(T)\n",
        "labels = labtrans.fit_transform(d_train,e_train)\n",
        "\n",
        "in_features = 125440\n",
        "num_nodes = [32, 32]\n",
        "out_features = labtrans.out_features\n",
        "batch_norm = True\n",
        "dropout = 0.1\n",
        "batch_size=12\n",
        "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
        "model2 = DeepHitSingle(net, tt.optim.Adam, alpha=0.2, sigma=0.1, duration_index=labtrans.cuts)"
      ],
      "metadata": {
        "id": "8NMYMxv41ojr"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.load_net('/content/gdrive/MyDrive/dataset/Survival/Models/gmv_longitudnal.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5rjaH5VIebL",
        "outputId": "6db35cee-a8f6-4f2a-81c2-50e1753c8364"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPVanilla(\n",
              "  (net): Sequential(\n",
              "    (0): DenseVanillaBlock(\n",
              "      (linear): Linear(in_features=125440, out_features=32, bias=True)\n",
              "      (activation): ReLU()\n",
              "      (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): DenseVanillaBlock(\n",
              "      (linear): Linear(in_features=32, out_features=32, bias=True)\n",
              "      (activation): ReLU()\n",
              "      (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "H72ym88n1xb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if mode != 'mat':\n",
        "  model2.optimizer.set_lr(0.00009)\n",
        "  epochs = 100\n",
        "  callbacks = [tt.callbacks.EarlyStopping()]\n",
        "  log = model2.fit(x_train, labels, batch_size, epochs, callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQBucbPD1yYz",
        "outputId": "db3b8629-e650-42a8-b98f-1b04ead77794"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\t[1s / 1s],\t\ttrain_loss: 0.1929\n",
            "1:\t[1s / 3s],\t\ttrain_loss: 0.1175\n",
            "2:\t[1s / 4s],\t\ttrain_loss: 0.1034\n",
            "3:\t[1s / 5s],\t\ttrain_loss: 0.0935\n",
            "4:\t[1s / 6s],\t\ttrain_loss: 0.0902\n",
            "5:\t[1s / 7s],\t\ttrain_loss: 0.0841\n",
            "6:\t[1s / 8s],\t\ttrain_loss: 0.0759\n",
            "7:\t[1s / 10s],\t\ttrain_loss: 0.0777\n",
            "8:\t[1s / 11s],\t\ttrain_loss: 0.0718\n",
            "9:\t[1s / 12s],\t\ttrain_loss: 0.0736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "heH0Reqb117e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "surv = model2.interpolate(6).predict_surv_df(x_test)\n",
        "ev = EvalSurv(surv, d_test, e_test, censor_surv='km')\n",
        "ev.concordance_td('antolini')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTR0EW-UIjy7",
        "outputId": "2ce76b0d-e97b-4a2a-e6a3-9f53dd8ea5ed"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7180851063829787"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Saving"
      ],
      "metadata": {
        "id": "bCScsDaP15_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2.save_net('gmv_longitudnal.pt')\n",
        "scipy.io.savemat('/content/data/features_gmv_test.mat', {\"data\":x_test})\n",
        "scipy.io.savemat('/content/data/features_gmv_train.mat', {\"data\":x_train})\n",
        "scipy.io.savemat('/content/data/d_gmv_train.mat', {\"data\":d_train})\n",
        "scipy.io.savemat('/content/data/event_gmv_train.mat', {\"data\":e_train})\n",
        "scipy.io.savemat('/content/data/d_gmv_test.mat', {\"data\":d_test})\n",
        "scipy.io.savemat('/content/data/event_gmv_test.mat', {\"data\":e_test})"
      ],
      "metadata": {
        "id": "OwZhgbSb17U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 5"
      ],
      "metadata": {
        "id": "fHJF94FyoqsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "xRqADAUg2JXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#replace with your path\n",
        "if mode == 'mat':\n",
        "  x_train=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/genetic_data/features_train.mat')\n",
        "  x_test=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/genetic_data/features_test.mat')\n",
        "  y_train=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/genetic_data/y_train.mat')\n",
        "  y_test=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/genetic_data/y_test.mat')\n",
        "  mask_train=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/genetic_data/mask_test.mat')\n",
        "  mask_test=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/genetic_data/mask_train.mat')\n",
        "  e_train=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/genetic_data/e_train.mat')\n",
        "  e_test=scipy.io.loadmat('/content/gdrive/MyDrive/dataset/Survival/Data/genetic_data/e_test.mat')\n",
        "\n",
        "\n",
        "  x_train = np.array( x_train[\"data\"], dtype = 'float32' )\n",
        "  x_test = np.array( x_test[\"data\"], dtype = 'float32' )\n",
        "  y_train = np.array( y_train[\"data\"], dtype = 'float32' )\n",
        "  y_test = np.array( y_test[\"data\"], dtype = 'float32' )\n",
        "  mask_train = np.array( mask_train[\"data\"], dtype = 'float32' )\n",
        "  mask_test = np.array( mask_test[\"data\"], dtype = 'float32' )\n",
        "  e_train = np.array( e_train[\"data\"], dtype = 'float32' )\n",
        "  e_test = np.array( e_test[\"data\"], dtype = 'float32' )\n",
        "\n",
        "\n",
        "else:\n",
        "  x_train,x_test,y_train,y_test,mask_train,mask_test,e_train,e_test=train_test_split(x,E,mask,event,test_size=0.2)\n"
      ],
      "metadata": {
        "id": "_Mg85iv52IHy"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network"
      ],
      "metadata": {
        "id": "oF0lBG8Y1mY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "\n",
        "with tf.device(\"/cpu:0\"):\n",
        "\n",
        "    def output_of_lambda(input_shape):\n",
        "        shape = list(input_shape)\n",
        "        return (shape[0], J)\n",
        "\n",
        "    def weibull_cdf(parameters):\n",
        "        m = parameters[:,0]\n",
        "        s = tf.maximum( parameters[:,1], 0.001 )\n",
        "        output_list = []\n",
        "        for num in range( J ):\n",
        "            Time   = tf.constant( num, dtype=\"float32\")\n",
        "            e_Time = tf.pow( Time, m )\n",
        "            s_Time = tf.negative( tf.divide( e_Time, s) )\n",
        "            x = tf.subtract( tf.constant(1, dtype=\"float32\") , tf.exp( s_Time ) ) # F(t) = 1 - exp(-(t-g)^m/s) #ref http://www.mogami.com/notes/weibull.html\n",
        "            output_list.append ( x )\n",
        "        return tf.stack(output_list, axis=1)\n",
        "\n",
        "    def generator_loss(y_true, y_pred, weights):  # y_true's shape=(batch_size, row, col, ch)\n",
        "        #loss = tf.cumsum( tf.multiply( tf.square( tf.subtract( y_pred, y_true ) ), weights ), axis=1, reverse=True)[:,0]\n",
        "        log_p = tf.math.log( tf.add( y_pred,  tf.constant(1.0) ) )\n",
        "        log_t = tf.math.log( tf.add( y_true,  tf.constant(1.0) ) )\n",
        "        loss = tf.cumsum( tf.multiply( tf.square( tf.subtract( log_p, log_t ) ), weights ), axis=1, reverse=True)[:,0]\n",
        "        return loss\n",
        "\n",
        "    def wrapped_generator_loss(func, *args, **kwargs):\n",
        "        partial_generator_loss = partial(generator_loss, *args, **kwargs)\n",
        "        update_wrapper(partial_generator_loss, generator_loss)\n",
        "        return partial_generator_loss\n",
        "\n",
        "    inputs = Input((n_features,), name='inputs')\n",
        "    x1 = Dense(units=32, activation='relu', name='hidden_layer1',\n",
        "                kernel_regularizer=regularizers.l1_l2(0.001))(inputs)\n",
        "    x1 = Dropout(DROPOUT_RATIO)(x1)\n",
        "    x2 = Dense(units=32, activation='relu', name='hidden_layer2',\n",
        "                kernel_regularizer=regularizers.l1_l2(0.001))(x1)\n",
        "    x2 = Dropout(DROPOUT_RATIO)(x2)\n",
        "    x3 = Dense(units=32, activation='relu', name='hidden_layer3',\n",
        "                kernel_regularizer=regularizers.l1_l2(0.001))(x2)\n",
        "    x3 = Dropout(DROPOUT_RATIO)(x3)\n",
        "    p1 = Dense(units=1, activation='softplus', name='param1_layer')(x3)\n",
        "    p2 = Dense(units=1, activation='relu', name='param2_layer')(x3)\n",
        "    parameters = Concatenate(name='params_layer')([p1, p2])\n",
        "    y_pred = Lambda(weibull_cdf, output_shape=output_of_lambda)(parameters)\n",
        "\n",
        "    mask_batch = Input((J,), name='mask_bartch')\n",
        "    L = wrapped_generator_loss(generator_loss, weights = mask_batch)\n",
        "\n",
        "    model = Model(inputs= [inputs, mask_batch], outputs = y_pred)\n",
        "    # model.summary()"
      ],
      "metadata": {
        "id": "R3bWdO6S4T_a"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/gdrive/MyDrive/dataset/Survival/Models/genetic_model', compile=False)"
      ],
      "metadata": {
        "id": "pfDDjgniKQRj"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "CHrKSnum4a9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_params = np.zeros([nn,2])\n",
        "c_index_test = np.zeros([J,1])\n",
        "outputfilename     = 'Training.csv'\n",
        "weightfilename     = 'WeightBest.h5'\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "features_train = scaler.transform(x_train)\n",
        "features_test = scaler.transform(x_test)\n",
        "checkpointer = ModelCheckpoint(filepath=weightfilename, monitor='loss', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "DsKys_Yi4fGt"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(patience=10,verbose=1)\n",
        "callbacks = []\n",
        "callbacks.append(early_stopping)\n",
        "adm = optimizers.Adam(lr=0.00003, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model.compile(optimizer=adm, loss=L)\n",
        "# model.run_eagerly = True\n",
        "if mode != 'mat':\n",
        "  model.fit([features_train, mask_train], y_train, batch_size=12, epochs = 100, callbacks=callbacks, verbose=0)\n",
        "  model.save_weights('Model_Weights_' + str(num+1) + '.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52wm87-z4h8Q",
        "outputId": "8f4eec91-dcf4-4314-db94-3bb84f1027d9"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "-QoX5SCX4b0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prob = model.predict([features_test, mask_test], batch_size=12, verbose=1)\n",
        "\n",
        "c_index = np.zeros([J])\n",
        "for num in range(J - 1) :\n",
        "\n",
        "    c_index[num+1] = concordance_index(y_test[:,num+1],1/prob[:,num+1])\n",
        "print( np.mean(c_index ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmZoMH_8KcKn",
        "outputId": "d09a8def-8bdf-4247-e757-7b2532c906eb"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 18ms/step\n",
            "0.7090909090909092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Save"
      ],
      "metadata": {
        "id": "5xBSXeo_4dDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scipy.io.savemat('/content/genetic_data/features_test.mat', {\"data\":x_test})\n",
        "scipy.io.savemat('/content/genetic_data/features_train.mat', {\"data\":x_train})\n",
        "scipy.io.savemat('/content/genetic_data/y_train.mat', {\"data\":y_train})\n",
        "scipy.io.savemat('/content/genetic_data/y_test.mat', {\"data\":y_test})\n",
        "\n",
        "scipy.io.savemat('/content/genetic_data/mask_test.mat', {\"data\":mask_train})\n",
        "scipy.io.savemat('/content/genetic_data/mask_train.mat', {\"data\":mask_test})\n",
        "scipy.io.savemat('/content/genetic_data/e_train.mat', {\"data\":e_train})\n",
        "scipy.io.savemat('/content/genetic_data/e_test.mat', {\"data\":e_test})\n",
        "\n",
        "model.save('genetic_model')\n"
      ],
      "metadata": {
        "id": "TsatBF4Uz71y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}